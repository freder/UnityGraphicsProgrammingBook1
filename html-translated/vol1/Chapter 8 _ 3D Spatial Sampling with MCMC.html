<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ops="http://www.idpf.org/2007/ops" xml:lang="en" style="height: 100%;" class="translated-ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <link rel="stylesheet" type="text/css" href="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/style.scss">
  <meta name="generator" content="Re:VIEW">
  <title>3D spatial sampling performed by MCMC</title>

			<style>
				img {
					max-width: 80vw;
					max-height: 80vh;
				}
			</style><style>
					.goog-te-banner-frame {
						display: none;
					}
				</style>
			<script>(function(){(function injection() {
  var pageLang = 'ja';
  var userLang = 'en';

  var uid = '1E07F158C6FA4460B352973E9693B329';
  var teId = 'TE_' + uid;
  var cbId = 'TECB_' + uid;

  function show() {
    window.setTimeout(function() {
      window[teId].showBanner(true);
    }, 10);
  }

  function newElem() {
    
  }

  if (window[teId]) {
    show();
  } else {
    if (!window.google || !google.translate ||
        !google.translate.TranslateElement) {
      if (!window[cbId]) {
        window[cbId] = function() {
          window[teId] = newElem();
          show();
        };
      }
      
    }
  }
})();})();</script><script src="https://translate.google.com/translate_a/element.js?cb=TECB_1E07F158C6FA4460B352973E9693B329&amp;client=tee&amp;hl=en"></script><script src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/f.txt"></script><link type="text/css" rel="stylesheet" charset="UTF-8" href="https://translate.googleapis.com/translate_static/css/translateelement.css"><script type="text/javascript" charset="UTF-8" src="https://translate.googleapis.com/translate_static/js/element/main.js"></script><link type="text/css" rel="stylesheet" charset="UTF-8" href="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/translateelement.css"><script type="text/javascript" charset="UTF-8" src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/main.js"></script><script type="text/javascript" charset="UTF-8" src="https://translate.googleapis.com/element/TE_20201130_00/e/js/element/element_main.js"></script><script type="text/javascript" charset="UTF-8" src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/element_main.js"></script><script type="text/javascript" charset="UTF-8" src="https://translate.googleapis.com/element/TE_20201130_00/e/js/element/element_main.js"></script><link type="text/css" rel="stylesheet" charset="UTF-8" href="https://translate.googleapis.com/translate_static/css/translateelement.css"><script type="text/javascript" charset="UTF-8" src="https://translate.googleapis.com/translate_static/js/element/main.js"></script><script type="text/javascript" charset="UTF-8" src="https://translate.googleapis.com/element/TE_20201130_00/e/js/element/element_main.js"></script></head>
		
<body style="position: relative; min-height: 100%; top: 40px;"><div class="skiptranslate" style=""><iframe id=":0.container" class="goog-te-banner-frame skiptranslate" frameborder="0" src="javascript:''" style="visibility:visible"></iframe></div><div class="skiptranslate" style=""><iframe id=":0.container" class="goog-te-banner-frame skiptranslate" frameborder="0" src="javascript:''" style="visibility:visible"></iframe></div><div class="skiptranslate" style=""><iframe id=":0.container" class="goog-te-banner-frame skiptranslate" frameborder="0" src="javascript:''" style="visibility:visible"></iframe></div>
<h1><a id="h8"></a><span class="secno"><font style="vertical-align: inherit;"><font class="" style="vertical-align: inherit;">Chapter 8　</font></font></span><font style="vertical-align: inherit;"><font class="" style="vertical-align: inherit;"> 3D Spatial Sampling with MCMC</font></font></h1>

<h2><a id="h8-1"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.1　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Introduction</font></font></h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this chapter, we will explain the sampling method. </font><font style="vertical-align: inherit;">This time, we will focus on a sampling method called MCMC (Markov Chain Monte Carlo), which samples multiple appropriate values ​​from a certain probability distribution.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The simplest method for sampling from a certain probability distribution is the rejection method, but sampling in a three-dimensional space has a large rejected area and cannot withstand actual operation. </font><font style="vertical-align: inherit;">Therefore, the content of this chapter is that by using MCMC, sampling can be performed efficiently even in high dimensions.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As for the information about MCMC, on the one hand, systematic information such as books is for statisticians, and there is no guide to implementation for programmers, although it is redundant, and on the other hand, the information on the net has more than 10 lines of sample code. The reality is that there is no content that allows you to quickly and comprehensively understand the theory and implementation, as it is only described and there is no care for the theoretical background. </font><font style="vertical-align: inherit;">I tried to make the concrete explanations in the following sections as such as possible.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The explanation of the probability that is the background of MCMC is enough to write one book if it is strictly speaking. </font><font style="vertical-align: inherit;">This time, with the motto of explaining the minimum theoretical background that can be implemented with peace of mind, we aimed for an intuitive expression with moderate strictness of definition. </font><font style="vertical-align: inherit;">I think that if you have used mathematics in the first year of university or even a little at work, you can read the program without difficulty.</font></font></p>

<h2><a id="h8-2"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.2　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sample repository</font></font></h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this chapter, the Unity project of Unity Graphics Programming https://github.com/IndieVisualLab/Assets/ProceduralModeling in UnityGraphicsProgramming is prepared as a sample program.</font></font></p>

<h2><a id="h8-3"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.3　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Basic knowledge about probability</font></font></h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To understand the theory of MCMC, we first need to understand the basics of probability. </font><font style="vertical-align: inherit;">However, there are few concepts to keep in mind in order to understand MCMC this time, only the following four. </font><font style="vertical-align: inherit;">No likelihood or probability density function required!</font></font></p>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Random variable</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Probability distribution</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stochastic process</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stationary distribution</font></font></li>
</ul>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's look at them in order.</font></font></p>

<h3><a id="h8-3-1"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.3.1　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Random variables</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When an event occurs at establishment P (X), this real number X is called a random variable. </font><font style="vertical-align: inherit;">For example, when "the probability of getting a 5 on a dice is 1/6", "5" is a random variable and "1/6" is a probability. </font><font style="vertical-align: inherit;">In general, the previous sentence can be rephrased as "the probability that an X on the dice will appear is P (X)".</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">By the way, if you write it a little like a definition, the random variable X is a mapping X that returns a real number X for the element ω (= one event that happened) selected from the sample space Ω (= all the events that can occur). You can write = X (ω).</font></font></p>

<h3><a id="h8-3-2"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.3.2　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Stochastic process</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I added a slightly confusing definition in the latter half of the random variable because it makes it easier to understand the stochastic process on the assumption that the random variable X is represented by the notation X = X (ω). </font><font style="vertical-align: inherit;">The stochastic process is the one that can be expressed as X = X (ω, t) by adding the time condition to X. </font><font style="vertical-align: inherit;">In other words, the stochastic process can be thought of as a kind of random variable with a time condition.</font></font></p>

<h3><a id="h8-3-3"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.3.3　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Probability distribution</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The probability distribution shows the correspondence between the random variable X and the probability P (X). </font><font style="vertical-align: inherit;">It is often represented by a graph with probability P (X) on the vertical axis and X on the horizontal axis.</font></font></p>

<h3><a id="h8-3-4"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.3.4　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Stationary distribution</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Each point is a distribution in which the overall distribution does not change even if it transitions. </font><font style="vertical-align: inherit;">For a transition matrix π with a distribution P, P that satisfies πP = P is called a stationary distribution. </font><font style="vertical-align: inherit;">This definition alone is confusing, but it is clear from the figure below.</font></font></p>
<div id="komiettyfig04" class="image">
<img src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/komiettyfig04.png" alt="stationaryDistribution">
<p class="caption">
図8.1: stationaryDistribution
</p>
</div>

<h2><a id="h8-4"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.4　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> MCMC concept</font></font></h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now, in this section, we will touch on the concepts that make up MCMC. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As mentioned at the beginning, MCMC is a method of sampling an appropriate value from a certain probability distribution, but more specifically, the Monte Carlo method under the condition that the given distribution is a steady distribution. (Monte Carlo) and Markov chain (Markov chain) sampling method. </font><font style="vertical-align: inherit;">Below, we will explain the Monte Carlo method, Markov chain, and stationary distribution in that order.</font></font></p>

<h3><a id="h8-4-1"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.4.1　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Monte Carlo method</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Monte Carlo method is a general term for numerical calculations and simulations that use pseudo-random numbers. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An example that is often used to introduce numerical calculations using the Monte Carlo method is the following calculation of pi.</font></font></p>
<div class="emlist-code">
<pre class="emlist">float pi;<font></font>
float trial = 10000;<font></font>
float count = 0;<font></font>
<font></font>
for(int i=0; i&lt;trial; i++){<font></font>
    float x = Random.value;<font></font>
    float y = Random.value;<font></font>
    if(x*x+y*y &lt;= 1) count++;<font></font>
}<font></font>
<font></font>
pi = 4 * count / trial;<font></font>
</pre>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In short, the ratio of the number of trials in a fan-shaped circle in a 1 x 1 square to the total number of trials is the area ratio, so the pi can be calculated from that. </font><font style="vertical-align: inherit;">As a simple example, this is also the Monte Carlo method.</font></font></p>

<h3><a id="h8-4-2"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.4.2　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Markov chain</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A Markov chain is a stochastic process that satisfies Markov properties, in which states can be described discretely. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Markov property is the property that the probability distribution of the future state of a stochastic process depends only on the current state and not on the past state.</font></font></p>
<div id="komiettyfig01" class="image">
<img src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/komiettyfig01.png" alt="MarkovChain">
<p class="caption"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Figure 8.2: Markov Chain
</font></font></p>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As shown in the above figure, in the Markov chain, the future state depends only on the current state and does not directly affect the past state.</font></font></p>

<h3><a id="h8-4-3"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.4.3　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Stationary distribution</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MCMC needs to use pseudo-random numbers to converge from an arbitrary distribution to a given stationary distribution. </font><font style="vertical-align: inherit;">This is because if you do not converge to a given distribution, you will sample from a different distribution each time, and if you do not have a stationary distribution, you will not be able to sample well in a chain. </font><font style="vertical-align: inherit;">In order for an arbitrary distribution to converge to a given distribution, the following two conditions must be met.</font></font></p>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Irreducibility: A condition that the distribution must not be divided into multiple parts. </font><font style="vertical-align: inherit;">When repeating the transition from a certain point on the probability distribution, there must be no unreachable point</font></font></li>
</ul>
<div id="komiettyfig02" class="image">
<img src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/komiettyfig02.png" alt="Irreducibility">
<p class="caption">
図8.3: Irreducibility
</p>
</div>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aperiodicity: The condition that any n can be returned to the original place in n times. </font><font style="vertical-align: inherit;">For example, in the distribution arranged on the circumference, there must be no condition that the transition can be made only by skipping one.</font></font></li>
</ul>
<div id="komiettyfig03" class="image">
<img src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/komiettyfig03.png" alt="Aperiodicity">
<p class="caption"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Figure 8.4: Aperiodicity
</font></font></p>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Any distribution that meets these two conditions can converge to a given stationary distribution. </font><font style="vertical-align: inherit;">This is called the ergodic nature of the Markov process.</font></font></p>

<h3><a id="h8-4-4"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.4.4　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Metropolis method</font></font></h3>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now, it is difficult to check whether the given distribution satisfies the ergonomics mentioned earlier, so in many cases, we will strengthen the conditions and investigate within the range that satisfies the condition of "detailed balance". </font><font style="vertical-align: inherit;">One of the Markov chain methods that achieves detailed balance is called the metropolis method.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The metropolis method samples by taking the following two steps.</font></font></p>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Select the transition destination candidate x with a pseudo-random number. </font><font style="vertical-align: inherit;">x is generated according to a distribution Q that satisfies Q (x | x') = Q (x' | x), and this distribution Q is called the proposed distribution. </font><font style="vertical-align: inherit;">The Gaussian distribution is often chosen as the proposed distribution.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A random number independent of 1 is generated, and if a certain criterion is satisfied using the random number, the transition destination candidate is adopted. </font><font style="vertical-align: inherit;">Specifically, for a uniform random number 0 &lt;= r &lt;1, ​​the ratio P (x') / P (x) of the probability value P (x) on the target distribution and the probability value P (x') of the transition candidate destination ) Transitions to the transition candidate destination if P (x') / P (x)&gt; r is satisfied.</font></font></li>
</ol>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The merit of the metropolis method is that even after the transition to the maximum value of the probability distribution is completed, if the value of r is small, the probability value transitions to the smaller one, so sampling proportional to the probability value can be performed around the maximum value.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">By the way, the Metropolis method is a kind of Metropolis-Hastings method (MH method). </font><font style="vertical-align: inherit;">The Metropolis method uses a symmetrical distribution for the proposed distribution, but the MH method does not.</font></font></p>

<h2><a id="h8-5"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.5　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 3D sampling</font></font></h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's take a look at the actual code excerpt and see how to implement MCMC.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">First, prepare a three-dimensional probability distribution. </font><font style="vertical-align: inherit;">This is called the target distribution. </font><font style="vertical-align: inherit;">This is the "target" distribution because it is the distribution you actually want to sample.</font></font></p>
<div class="emlist-code">
<pre class="emlist">void Prepare()<font></font>
{<font></font>
    var sn = new SimplexNoiseGenerator();<font></font>
    for (int x = 0; x &lt; lEdge; x++)<font></font>
        for (int y = 0; y &lt; lEdge; y++)<font></font>
            for (int z = 0; z &lt; lEdge; z++)<font></font>
            {<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
                var i = x + lEdge * y + lEdge * lEdge * z;</font></font></font></font><font></font>
                var val = sn.noise(x, y, z);<font></font>
                data[i] = new Vector4(x, y, z, val);<font></font>
            }<font></font>
}<font></font>
</pre>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This time, we adopted simplex noise as the target distribution.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Next, actually run MCMC.</font></font></p>
<div class="emlist-code">
<pre class="emlist">public IEnumerable&lt;Vector3&gt; Sequence(int nInit, int limit, float th)<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
{</font></font></font></font><font></font>
    Reset();<font></font>
<font></font>
    for (var i = 0; i &lt; nInit; i++)<font></font>
        Next(th);<font></font>
<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    for (var i = 0; i &lt;limit; i ++)</font></font></font></font><font></font>
    {<font></font>
        yield return _curr;<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
        Next(th);</font></font></font></font><font></font>
    }<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
}</font></font></font></font><font></font>
</pre>
</div>
<div class="emlist-code">
<pre class="emlist">public void Reset()<font></font>
{<font></font>
     for (var i = 0; _currDensity &lt;= 0f &amp;&amp; i &lt; limitResetLoopCount; i++)<font></font>
     {<font></font>
             _curr = new Vector3(<font></font>
               Scale.x * Random.value,<font></font>
               Scale.y * Random.value,<font></font>
               Scale.z * Random.value<font></font>
               );<font></font>
             _currDensity = Density(_curr);<font></font>
     }<font></font>
}<font></font>
</pre>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Run the process using a coroutine. </font><font style="vertical-align: inherit;">Since MCMC starts processing from a completely different place when one Markov chain ends, it can be conceptually considered as parallel processing. </font><font style="vertical-align: inherit;">This time, I use the Reset function to run another process after a series of processes. </font><font style="vertical-align: inherit;">By doing this, you will be able to sample well even if there are many maxima of the probability distribution.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the first part of the transition is likely to be a point away from the target distribution, this section is burn-in without sampling. </font><font style="vertical-align: inherit;">When the target distribution is sufficiently approached, sampling and transition set are performed a certain number of times, and when finished, another series of processing is started.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finally, it is the process of determining the transition. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since it is three-dimensional, the proposed distribution uses a trivariate standard normal distribution as follows.</font></font></p>
<div class="emlist-code">
<pre class="emlist">public static Vector3 GenerateRandomPointStandard()<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
{</font></font></font></font><font></font>
        var x = RandomGenerator.rand_gaussian(0f, 1f);<font></font>
        var y = RandomGenerator.rand_gaussian(0f, 1f);<font></font>
        var z = RandomGenerator.rand_gaussian(0f, 1f);<font></font>
        return new Vector3(x, y, z);<font></font>
}<font></font>
</pre>
</div>
<div class="emlist-code">
<pre class="emlist">public static float rand_gaussian(float mu, float sigma)<font></font>
{<font></font>
     float z = Mathf.Sqrt(-2.0f * Mathf.Log(Random.value))<font></font>
              * Mathf.Sin(2.0f * Mathf.PI * Random.value);<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
     return mu + sigma * z;</font></font></font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
}</font></font></font></font><font></font>
</pre>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the Metropolis method, the distribution must be symmetrical, so the mean value is not set to anything other than 0, but if the variance is set to something other than 1, it is derived as follows using the Cholesky decomposition. I will.</font></font></p>
<div class="emlist-code">
<pre class="emlist">public static Vector3 GenerateRandomPoint(Matrix4x4 sigma)<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
{</font></font></font></font><font></font>
    var c00 = sigma.m00 / Mathf.Sqrt(sigma.m00);<font></font>
    var c10 = sigma.m10 / Mathf.Sqrt(sigma.m00);<font></font>
    var c20 = sigma.m21 / Mathf.Sqrt(sigma.m00);<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    var c11 = Mathf.Sqrt (sigma.m11 - c10 * c10);</font></font></font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    var c21 = (sigma.m21 - c20 * c10) / c11;</font></font></font></font><font></font>
    var c22 = Mathf.Sqrt(sigma.m22 - (c20 * c20 + c21 * c21));<font></font>
    var r1 = RandomGenerator.rand_gaussian(0f, 1f);<font></font>
    var r2 = RandomGenerator.rand_gaussian(0f, 1f);<font></font>
    var r3 = RandomGenerator.rand_gaussian(0f, 1f);<font></font>
    var x = c00 * r1;<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    var y = c10 * r1 + c11 * r2;</font></font></font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
    var z = c20 * r1 + c21 * r2 + c22 * r3;</font></font></font></font><font></font>
    return new Vector3(x, y, z);<font></font>
}<font></font>
</pre>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To determine the transition destination, take the ratio of the probabilities of the proposed distribution (one point above) next and the immediately preceding point_curr on the target distribution, and if it is larger than a uniform random number, it will transition, otherwise it will not transition. I will. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the process of finding the probability value corresponding to the coordinates of the transition destination is heavy (the amount of processing of O (n ^ 3)), the probability value is approximated. </font><font style="vertical-align: inherit;">Since we are using a distribution in which the target distribution changes continuously this time, the established value is approximately derived by performing a weighted average that is inversely proportional to the distance.</font></font></p>
<div class="emlist-code">
<pre class="emlist">void Next(float threshold)<font></font>
{<font></font>
        Vector3 next =<font></font>
          GaussianDistributionCubic.GenerateRandomPointStandard()<font></font>
          + _curr;<font></font>
<font></font>
        var densityNext = Density(next);<font></font>
        bool flag1 =<font></font>
          _currDensity &lt;= 0f ||<font></font>
          Mathf.Min(1f, densityNext / _currDensity) &gt;= Random.value;<font></font>
        bool flag2 = densityNext &gt; threshold;<font></font>
        if (flag1 &amp;&amp; flag2)<font></font>
        {<font></font>
                _curr = next;<font></font>
                _currDensity = densityNext;<font></font>
        }<font></font>
}<font></font>
<font></font>
float Density(Vector3 pos)<font></font>
{<font></font>
        float weight = 0f;<font></font>
        for (int i = 0; i &lt; weightReferenceloopCount; i++)<font></font>
        {<font></font>
                int id = (int)Mathf.Floor(Random.value * (Data.Length - 1));<font></font>
                Vector3 posi = Data[id];<font></font>
                float mag = Vector3.SqrMagnitude(pos - posi);<font></font>
                weight += Mathf.Exp(-mag) * Data[id].w;<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
        }</font></font><font></font>
        return weight;<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
}</font></font></font></font><font></font>
</pre>
</div>

<h2><a id="h8-6"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.6　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Other</font></font></h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This time, the repository also contains a sample of the 3D rejection method (a simple Monte Carlo method as shown in the circle example), so it is a good idea to compare them. </font><font style="vertical-align: inherit;">With the rejection method, sampling cannot be done well if the rejection standard value is set stronger, whereas with MCMC, similar sampling results can be presented more smoothly. </font><font style="vertical-align: inherit;">Also, in MCMC, if the width of the random walk for each step is reduced, sampling is performed from a close space in a series of chains, so it is possible to easily reproduce a cluster of plants and flowers.</font></font></p>

<h2><a id="h8-7"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.7　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> References</font></font></h2>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Takuya Kubo (2012) Introduction to Statistical Modeling for Data Analysis: Generalized Linear Model, Hierarchical Bayes Model, MCMC (Science of Probability and Information) Iwanami Shoten</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Olle Haggstrom, Kentaro Nomaguchi (2017) Introduction to Easy MCMC: Limited Markov Chain and Algorithm Kyoritsu Shuppan</font></font></font></font></font></font></li>
</ul><div id="goog-gt-tt" class="goog-tooltip skiptranslate" dir="ltr" style="visibility: hidden; left: 53px; top: 30.125px; display: none;"><div style="padding: 8px;"><div><div class="logo"><img src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/translate_24dp.png" width="20" height="20" alt="Google Translate"></div></div></div><div class="top" style="padding: 8px; float: left; width: 100%;"><h1 class="title gray">Original text</h1></div><div class="middle" style="padding: 8px;"><div class="original-text">第8章　MCMCで行う３次元空間サンプリング</div></div><div class="bottom" style="padding: 8px;"><div class="activity-links"><span class="activity-link">Contribute a better translation</span><span class="activity-link"></span></div><div class="started-activity-container"><hr style="color: #CCC; background-color: #CCC; height: 1px; border: none;"><div class="activity-root"></div></div></div><div class="status-message" style="display: none; opacity: 0;"></div></div>


<div class="goog-te-spinner-pos"><div class="goog-te-spinner-animation"><svg xmlns="http://www.w3.org/2000/svg" class="goog-te-spinner" width="96px" height="96px" viewBox="0 0 66 66"><circle class="goog-te-spinner-path" fill="none" stroke-width="6" stroke-linecap="round" cx="33" cy="33" r="30"></circle></svg></div></div><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 1001px; height: 263px; display: none;" src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/saved_resource(1).html"></iframe><div id="goog-gt-tt" class="skiptranslate" dir="ltr"><div style="padding: 8px;"><div><div class="logo"><img src="https://www.gstatic.com/images/branding/product/1x/translate_24dp.png" width="20" height="20" alt="Google Translate"></div></div></div><div class="top" style="padding: 8px; float: left; width: 100%;"><h1 class="title gray">Original text</h1></div><div class="middle" style="padding: 8px;"><div class="original-text"></div></div><div class="bottom" style="padding: 8px;"><div class="activity-links"><span class="activity-link">Contribute a better translation</span><span class="activity-link"></span></div><div class="started-activity-container"><hr style="color: #CCC; background-color: #CCC; height: 1px; border: none;"><div class="activity-root"></div></div></div><div class="status-message" style="display: none;"></div></div><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 197px; height: 69px; display: none;" src="./Chapter 8 _ 3D Spatial Sampling with MCMC_files/saved_resource(2).html"></iframe><div id="goog-gt-tt" class="skiptranslate" dir="ltr"><div style="padding: 8px;"><div><div class="logo"><img src="https://www.gstatic.com/images/branding/product/1x/translate_24dp.png" width="20" height="20" alt="Google Translate"></div></div></div><div class="top" style="padding: 8px; float: left; width: 100%;"><h1 class="title gray">Original text</h1></div><div class="middle" style="padding: 8px;"><div class="original-text"></div></div><div class="bottom" style="padding: 8px;"><div class="activity-links"><span class="activity-link">Contribute a better translation</span><span class="activity-link"></span></div><div class="started-activity-container"><hr style="color: #CCC; background-color: #CCC; height: 1px; border: none;"><div class="activity-root"></div></div></div><div class="status-message" style="display: none;"></div></div><div class="goog-te-spinner-pos"><div class="goog-te-spinner-animation"><svg xmlns="http://www.w3.org/2000/svg" class="goog-te-spinner" width="96px" height="96px" viewBox="0 0 66 66"><circle class="goog-te-spinner-path" fill="none" stroke-width="6" stroke-linecap="round" cx="33" cy="33" r="30"></circle></svg></div></div><div id="goog-gt-tt" class="skiptranslate" dir="ltr"><div style="padding: 8px;"><div><div class="logo"><img src="https://www.gstatic.com/images/branding/product/1x/translate_24dp.png" width="20" height="20" alt="Google Translate"></div></div></div><div class="top" style="padding: 8px; float: left; width: 100%;"><h1 class="title gray">Original text</h1></div><div class="middle" style="padding: 8px;"><div class="original-text"></div></div><div class="bottom" style="padding: 8px;"><div class="activity-links"><span class="activity-link">Contribute a better translation</span><span class="activity-link"></span></div><div class="started-activity-container"><hr style="color: #CCC; background-color: #CCC; height: 1px; border: none;"><div class="activity-root"></div></div></div><div class="status-message" style="display: none;"></div></div><div class="goog-te-spinner-pos"><div class="goog-te-spinner-animation"><svg xmlns="http://www.w3.org/2000/svg" class="goog-te-spinner" width="96px" height="96px" viewBox="0 0 66 66"><circle class="goog-te-spinner-path" fill="none" stroke-width="6" stroke-linecap="round" cx="33" cy="33" r="30"></circle></svg></div></div><div class="goog-te-spinner-pos"><div class="goog-te-spinner-animation"><svg xmlns="http://www.w3.org/2000/svg" class="goog-te-spinner" width="96px" height="96px" viewBox="0 0 66 66"><circle class="goog-te-spinner-path" fill="none" stroke-width="6" stroke-linecap="round" cx="33" cy="33" r="30"></circle></svg></div></div><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 1001px; height: 263px; display: none;"></iframe><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 197px; height: 69px; display: none;"></iframe><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 1001px; height: 263px; display: none;"></iframe><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 197px; height: 69px; display: none;"></iframe></body></html>