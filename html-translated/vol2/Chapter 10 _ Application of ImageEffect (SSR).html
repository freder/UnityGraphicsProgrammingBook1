<!DOCTYPE html>
<!-- saved from url=(0044)https://freder.io/files/unity2/komietty.html -->
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ops="http://www.idpf.org/2007/ops" xml:lang="en" class="translated-ltr" style="height: 100%;"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <link rel="stylesheet" type="text/css" href="./Chapter 10 _ Application of ImageEffect (SSR)_files/style.scss">
  <meta name="generator" content="Re:VIEW">
  <title>ImageEffect application (SSR)</title>

			<style>
				img {
					max-width: 80vw;
					max-height: 80vh;
				}
			</style>
			<script>(function(){(function injection() {
  var pageLang = 'ja';
  var userLang = 'en';

  var uid = '1E07F158C6FA4460B352973E9693B329';
  var teId = 'TE_' + uid;
  var cbId = 'TECB_' + uid;

  function show() {
    window.setTimeout(function() {
      window[teId].showBanner(true);
    }, 10);
  }

  function newElem() {
    var elem = new google.translate.TranslateElement({
      autoDisplay: false,
      floatPosition: 0,
      multilanguagePage: true,
      pageLanguage: pageLang
    });
    return elem;
  }

  if (window[teId]) {
    show();
  } else {
    if (!window.google || !google.translate ||
        !google.translate.TranslateElement) {
      if (!window[cbId]) {
        window[cbId] = function() {
          window[teId] = newElem();
          show();
        };
      }
      var s = document.createElement('script');
      s.src = 'https://translate.google.com/translate_a/element.js?cb=' +
              encodeURIComponent(cbId) + '&client=tee&hl=' + userLang;
      document.getElementsByTagName('head')[0].appendChild(s);
    }
  }
})();})();</script><script src="./Chapter 10 _ Application of ImageEffect (SSR)_files/f.txt"></script><link type="text/css" rel="stylesheet" charset="UTF-8" href="./Chapter 10 _ Application of ImageEffect (SSR)_files/translateelement.css"><script type="text/javascript" charset="UTF-8" src="./Chapter 10 _ Application of ImageEffect (SSR)_files/main.js"></script><script type="text/javascript" charset="UTF-8" src="./Chapter 10 _ Application of ImageEffect (SSR)_files/element_main.js"></script></head>
		
<body style="position: relative; min-height: 100%; top: 40px;"><div class="skiptranslate" style=""><iframe id=":0.container" class="goog-te-banner-frame skiptranslate" frameborder="0" src="javascript:&#39;&#39;" style="visibility:visible" src="./Chapter 10 _ Application of ImageEffect (SSR)_files/saved_resource.html"></iframe></div>
<h1><a id="h10"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chapter 10 Application of　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ImageEffect (SSR)</font></font></h1>

<h2><a id="h10-1"></a><span class="secno"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10.1　</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Introduction</font></font></h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This chapter describes the theory and implementation of Screen Space Reflection as an application of ImageEffect. </font><font style="vertical-align: inherit;">When constructing a three-dimensional space, reflections and reflections are useful for expressing reality along with shadows. </font><font style="vertical-align: inherit;">However, despite the simplicity of the phenomena we see in our daily lives, reflections and reflections are enormous calculations when trying to faithfully reproduce physical phenomena using ray tracing (described later) in the world of 3DCG. It is also an expression that requires quantity. </font><font style="vertical-align: inherit;">Recently, Octan Renderer has become available in Unity, and when producing as a video work, it has become possible to produce quite photorealistic effects in Unity, but in real-time rendering it is still necessary to devise a pseudo reproduction. There is.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are several techniques for expressing reflections with real-time rendering, but in this chapter we will introduce a technique called Screen Space Reflection (SSR) that belongs to the post-effects.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As for the structure of this chapter, we will first explain the blur processing used in the sample program in advance as a shoulder break-in for post effects. </font><font style="vertical-align: inherit;">After that, I will explain SSR while breaking it down into the smallest possible processing units.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In addition, the sample of this chapter is </font><font style="vertical-align: inherit;">in "SSR" of </font></font><br><a href="https://github.com/IndieVisualLab/UnityGraphicsProgramming2" class="link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://github.com/IndieVisualLab/UnityGraphicsProgramming2</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></p>

<h2><a id="h10-2"></a><span class="secno">10.2　</span>Blur</h2>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this section, we will explain the blur processing. </font><font style="vertical-align: inherit;">If you include anti-aliasing, you need to understand the procedure that blurring is very complicated, but this time it is a basic process because it is a shoulder break-in. </font><font style="vertical-align: inherit;">The basis of blur processing is </font><font style="vertical-align: inherit;">to homogenize the color of texels by multiplying </font><font style="vertical-align: inherit;">each texel (pixels after rasterization </font></font><a id="fnb-texel" href="https://freder.io/files/unity2/komietty.html#fn-texel" class="noteref" epub:type="noteref"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">* 4</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) of the </font><font style="vertical-align: inherit;">image to be processed by </font><font style="vertical-align: inherit;">a matrix that refers to the texels around it. I will continue. </font><font style="vertical-align: inherit;">The matrix that references the texels around this is called the kernel. </font><font style="vertical-align: inherit;">The kernel is a matrix that determines the proportion of texel colors mixed.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gaussian blur is the most commonly used blur treatment. </font><font style="vertical-align: inherit;">As the name implies, this refers to the process of using a Gaussian distribution in the kernel. </font><font style="vertical-align: inherit;">Read the Gaussian Blur implementation diagonally to get a feel for how it works in post-effects.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Gaussian kernel mixes the brightness around the pixel to be processed at a rate that follows a Gaussian distribution. </font><font style="vertical-align: inherit;">By doing this, it is possible to suppress the blurring of the contour part where the brightness changes non-linearly.</font></font></p>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As a review of mathematics, the Gaussian distribution can be expressed by the following formula.</font></font></p>
<div class="equation">
<pre>G\left( x\right) =\dfrac {1}{\sqrt {2 \pi \sigma ^{2}}}\exp \left( -\dfrac {x^{2}}{2\sigma ^{2}}\right)
</pre>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the Gaussian distribution can be approximated to the binomial distribution here, the Gaussian distribution can be substituted by the combination of weighting according to the binomial distribution as shown below (see footnote </font></font><a id="fnb-binomial" href="https://freder.io/files/unity2/komietty.html#fn-binomial" class="noteref" epub:type="noteref"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">* 2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> for the approximation of the Gaussian and binomial distributions </font><font style="vertical-align: inherit;">).</font></font></p>
<div class="emlist-code">
<p class="caption">GaussianBlur.shader</p>
<pre class="emlist">float4 x_blur (v2f i) : SV_Target<font></font>
{<font></font>
  float weight [5] = { 0.2270270, 0.1945945, 0.1216216, 0.0540540, 0.0162162 };<font></font>
  float offset [5] = { 0.0, 1.0, 2.0, 3.0, 4.0 };<font></font>
  float2 size = _MainTex_TexelSize;<font></font>
  fixed4 col = tex2D(_MainTex, i.uv) * weight[0];<font></font>
  for(int j=1; j&lt;5; j++)<font></font>
  {<font></font>
    col += tex2D(_MainTex, i.uv + float2(offset[j], 0) * size) * weight[j];<font></font>
    col += tex2D(_MainTex, i.uv - float2(offset[j], 0) * size) * weight[j];<font></font>
  }<font></font>
  return col;<font></font>
}<font></font>
</pre>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The above code is only in the x direction, but the processing is almost the same in the y direction. </font><font style="vertical-align: inherit;">Here, the blur in the x and y directions is divided into two directions, and the number of brightness acquisitions </font><font style="vertical-align: inherit;">is reduced </font><font style="vertical-align: inherit;">from </font><span class="equation"><font style="vertical-align: inherit;">n * </font></span></font><span class="equation"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n = n ^ 2</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> times to </font></font><span class="equation"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n * 2 + 1 = 2n + 1</font></font></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> times. Because you can.</font></font></p>
<div id="id_komietty_2Fssr__blur" class="image">
<img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/ssr_blur.png" alt="Confirmation that blur is applied correctly by synthesizing Blur in each direction">
<p class="caption"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Figure 10.1: Confirmation that Blur composition in each direction correctly blurs
</font></font></p>
</div>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On the script side, </font></font><code class="inline-code tt">OnRenderImage</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Blit alternately between src and temporary RenderTexture in each direction of xy, and finally Blit from src to dst and output. </font><font style="vertical-align: inherit;">On MacOS, Blitt was possible only with src, but on Windows, the result was not output, so </font></font><code class="inline-code tt">RenderTexture.GetTemporary</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I am using. </font><font style="vertical-align: inherit;">(For OnRenderImage and Blit, refer to the introduction to ImageEffect in the previous chapter.)</font></font></p>
<div class="emlist-code">
<p class="caption">GaussianBlur.cs</p>
<pre class="emlist">void OnRenderImage(RenderTexture src, RenderTexture dst)<font></font>
{<font></font>
  var rt = RenderTexture.GetTemporary(src.width, src.height, 0, src.format);<font></font>
<font></font>
  for (int i = 0; i &lt; blurNum; i++)<font></font>
  {<font></font>
    Graphics.Blit(src, rt, mat, 0);<font></font>
    Graphics.Blit(rt, src, mat, 1);<font></font>
  }<font></font>
  Graphics.Blit(src, dst);<font></font>
<font></font>
  RenderTexture.ReleaseTemporary(rt);<font></font>
}<font></font>
</pre>
</div>
<p>以上でガウシアンブラーの解説は終わりです。ポストエフェクトがどのように行われるかの感覚が掴めてきたかと思いますので、次節からSSRの解説を行います。</p>

<h2><a id="h10-3"></a><span class="secno">10.3　</span>SSR</h2>
<p>SSRはポストエフェクトの範囲内で反射・映り込みを再現しようとするテクニックです。SSRに必要なのはカメラで撮られた画そのものと、深度情報が書き込まれたデプスバッファ、あとは法線情報が書き込まれたノーマルバッファです。デプスバッファやノーマルバッファなどはG-bufferと総称されるもので、SSRのようなDeferredレンダリングにとっては必要不可欠なものとなります。（Deferredレンダリングについては前章のImageEffect入門に素晴らしい解説がありますので、ぜひそちらを参照してください。）</p>
<p>本節を読む際の前提ですが、本節ではレイトレーシングについての基本的な知識を前提にして解説を進めていきます。レイトレーシングについては、入門レベルでも別にもう一章書けるくらい大きなテーマなので、残念ながらここでは説明は割愛させていただきます。ただ、レイトレーシングが何か分からないと以下の内容も理解できないので、分からないという方はPeterShirleyの良入門書 "Ray Tracing in One Weekend"<a id="fnb-shirley" href="https://freder.io/files/unity2/komietty.html#fn-shirley" class="noteref" epub:type="noteref">*3</a>がありますので、先ずそちらを読まれることをおすすめします。</p>
<p>また、SSRのUnity実装での解説テキストとしてはkode80の「Screen Space Reflections in Unity 5 <a id="fnb-kode80" href="https://freder.io/files/unity2/komietty.html#fn-kode80" class="noteref" epub:type="noteref">*6</a>」が有名です。また日本語のテキストでは「Unity で Screen Space Reflection の実装をしてみた <a id="fnb-hecomi" href="https://freder.io/files/unity2/komietty.html#fn-hecomi" class="noteref" epub:type="noteref">*8</a>」があります。本節では上記のテキストで解説されていることは、極力解説を簡略化したり、枝葉のテクニックについては解説を省略しています。ソースコードを読んで不明点が合った場合は、これらを当たるようにしてみて下さい。</p>

<h3><a id="h10-3-1"></a><span class="secno">10.3.1　</span>理論概観</h3>
<p>SSRの基本的な考え方は、レイトレーシングのテクニックを使い、カメラ、反射表面、オブジェクト（光源）、の関係をシミュレートするものです。</p>
<p>SSRでは通常の光学と異なり、カメラに入射する光の道筋から逆算することで、光源を特定した後、反射面にその色をフェッチしてくることで、反射面に反射が再現されます。</p>
<div id="id_komietty_2Fssr__idea" class="image">
<img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/ssr_idea.png" alt="Difference between real optics and SSR light thinking">
<p class="caption">
図10.2: 現実の光学とSSRの光の考え方の違い
</p>
</div>
<p>SSRではカメラの各ピクセルに対して、これを行います。</p>
<p>処理の大筋は以下のようにまとめることができます。</p>
<ol>
<li>スクリーン座標系を、深度情報を用いることでワールド座標系に戻す</li>
<li>視線ベクトルと法線情報から、反射ベクトルを求める</li>
<li>反射ベクトルを少しだけ伸ばし、その先端（＝レイ）の位置を再度スクリーン座標系に戻す</li>
<li>スクリーン座標系のレイの位置について、レイの深度とデプスバッファに書き込まれている深度を比較する</li>
<li>レイの方が深度が小さい場合、レイはまだ空中をさまよっている状態。３に戻りレイをもう少し進める</li>
<li>レイの方が深度が大きい場合、レイがなんらか物体を通過したということなので、反射される色を取得できる</li>
<li>もとのピクセルに戻り、取得した色を反映する</li>
</ol>
<p>図では説明しにくい手続きですが、言葉で説明してもややこしいですね。分解して見ていきましょう。</p>

<h3><a id="h10-3-2"></a><span class="secno">10.3.2　</span>座標変換</h3>
<p>先ずはスクリーン座標系とワールド座標系とを変換するための行列をシェーダーに渡してあげます。<code class="inline-code tt">_ViewProj</code> がワールド座標系からスクリーン座標系への変換行列、<code class="inline-code tt">_InvViewProj</code> はその逆行列になります。</p>
<div class="emlist-code">
<p class="caption">SSR.cs</p>
<pre class="emlist">void OnRenderImage(RenderTexture src, RenderTexture dst)<font></font>
{<font></font>
<font></font>
  ....<font></font>
<font></font>
  // world &lt;-&gt; screen matrix<font></font>
  var view = cam.worldToCameraMatrix;<font></font>
  var proj = GL.GetGPUProjectionMatrix(cam.projectionMatrix, false);<font></font>
  var viewProj = proj * view;<font></font>
  mat.SetMatrix("_ViewProj", viewProj);<font></font>
  mat.SetMatrix("_InvViewProj", viewProj.inverse);<font></font>
<font></font>
  ....<font></font>
<font></font>
}<font></font>
</pre>
</div>
<p>さて渡された変換行列を用いて、法線ベクトルと反射ベクトルが求まります。該当するシェーダーの処理を見てみましょう。</p>
<div class="emlist-code">
<p class="caption">SSR.shader</p>
<pre class="emlist">float4 reflection (v2f i) : SV_Target<font></font>
{<font></font>
  float2 uv = i.screen.xy / i.screen.w;<font></font>
  float depth = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, uv);<font></font>
<font></font>
  ...<font></font>
<font></font>
  float2 screenpos = 2.0 * uv - 1.0;<font></font>
  float4 pos = mul(_InvViewProj, float4(screenpos, depth, 1.0));<font></font>
  pos /= pos.w;<font></font>
  float3 camDir = normalize(pos - _WorldSpaceCameraPos);<font></font>
  float3 normal = tex2D(_CameraGBufferTexture2, uv) * 2.0 - 1.0;<font></font>
  float3 refDir = reflect(camDir, normal);<font></font>
<font></font>
  ....<font></font>
<font></font>
  if (_ViewMode == 1) col = float4((normal.xyz * 0.5 + 0.5), 1);<font></font>
  if (_ViewMode == 2) col = float4((refDir.xyz * 0.5 + 0.5), 1);<font></font>
<font></font>
  ....<font></font>
<font></font>
  return col;<font></font>
  }<font></font>
</pre>
</div>
<p>まず該当ピクセルの深度は <code class="inline-code tt">_CameraDepthTexture</code> に書き込まれており、これ利用します。つぎにスクリーン上の位置情報と震度情報から、該当ピクセルに写っているポリゴンのワールド座標系での位置が分かるので、これを <code class="inline-code tt">pos</code> に保持します。<code class="inline-code tt">pos</code> と <code class="inline-code tt">_WorldSpaceCameraPos</code> から、カメラへ向かうベクトルが分かるので、これと法線情報から、反射ベクトルが分かるようになります。</p>
<p>メインカメラにアタッチされたスクリプトから、法線ベクトルと反射ベクトルがどこを向いているかを確認できるようになってます。各ベクトルとも -1 ~ 1 の間に規格化されているため、0以下の値の色情報は表示されません。ベクトルがｘ軸成分が大きいときは赤っぽく、ｙ軸成分が大きいときは緑っぽく、ｚ軸成分が大きいときは青っぽく表示されます。ViewMode を <code class="inline-code tt">Normal</code> もしくは　<code class="inline-code tt">Reflection</code> にして確認してみて下さい。</p>

<h3><a id="h10-3-3"></a><span class="secno">10.3.3　</span>レイトレーシング</h3>
<p>では次にレイトレーシングを行う処理を見ていきましょう。</p>
<div class="emlist-code">
<p class="caption">SSR.shader</p>
<pre class="emlist">float4 reflection(v2f i) : SV_Target<font></font>
{<font></font>
<font></font>
  ...<font></font>
<font></font>
  [loop]<font></font>
  for (int n = 1; n &lt;= _MaxLoop; n++)<font></font>
  {<font></font>
    float3 step = refDir * _RayLenCoeff * (lod + 1);<font></font>
    ray += step * (1 + rand(uv + _Time.x) * (1 - smooth));<font></font>
<font></font>
    float4 rayScreen  = mul(_ViewProj, float4(ray, 1.0));<font></font>
    float2 rayUV      = rayScreen.xy / rayScreen.w * 0.5 + 0.5;<font></font>
    float  rayDepth   = ComputeDepth(rayScreen);<font></font>
    float  worldDepth = (lod == 0)?<font></font>
           SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, rayUV) :<font></font>
           tex2Dlod(_CameraDepthMipmap, float4(rayUV, 0, lod))<font></font>
           + _BaseRaise * lod;<font></font>
<font></font>
    ...<font></font>
<font></font>
    if(rayDepth &lt; worldDepth)<font></font>
    {<font></font>
<font></font>
      ....<font></font>
<font></font>
      return outcol;<font></font>
    }<font></font>
  }<font></font>
}<font></font>
</pre>
</div>
<p>後に説明する処理に関係する変数も混じっていますが、気にせず読み進めて下さい。ループ内では、まずレイをステップ分だけ伸ばしてあげ、それを再度スクリーン座標系に戻します。スクリーン座標系でのレイの深度と、デプスバッファに書き込まれた深度を比較して、レイの方が奥にある場合、その色を返すことにします。（デプスは最も近い時1.0で、遠くなるほど小さくなるので、<code class="inline-code tt">rayDepth</code> が <code class="inline-code tt">worldDepth</code> よりも小さい時、レイが奥にあるという判定になります。）</p>
<p>またループ回数が未定の場合はHLSLはエラーを吐くので、スクリプトからループの回数を渡したい場合は <code class="inline-code tt">[loop]</code> アトリビュートを先頭に書いておく必要があります。</p>
<p>レイトレーシングの骨組みの部分は以上で完成です。基本的な処理はイメージさえできてしまえばそんなに難しくありません。ただし、きれいな反射を再現するためには、これからいくつか処理を追加していく必要があります。重要な改善すべきポイントとしては以下の４つが挙げられるでしょうか。</p>
<ol>
<li>ループ数に制限があるため、レイが進める距離が十分大きくならなず、遠くの物体の映り込みが再現できない</li>
<li>レイのステップ数が大きくなると、映り込むオブジェクトを通過してしまい、間違った色をサンプリングしてしまう</li>
<li>ループを多数回行うので、単純に処理が重い</li>
<li>マテリアルの差異を考慮できていない</li>
</ol>
<p>アンチエイリアスを含むポストエフェクトでは、処理の効率化のためのテクニックがむしろ本質的です。処理の骨子の理解が済んだところで、SSRを映像として成立させるテクニックを見ていきましょう。</p>

<h3><a id="h10-3-4"></a><span class="secno">10.3.4　</span>Mipmap</h3>
<p>以下では Chalmers University of Technologyの記事 <a id="fnb-chalmers" href="https://freder.io/files/unity2/komietty.html#fn-chalmers" class="noteref" epub:type="noteref">*7</a> を参考に、Mipmap使うことで処理効率をあげる方法について解説します。(Mipmapが何かについては脚注参照 <a id="fnb-mipmap" href="https://freder.io/files/unity2/komietty.html#fn-mipmap" class="noteref" epub:type="noteref">*9</a>)レイトレーシングはレイのステップ幅を決めてレイを徐々に進めていくのが基本ですが、Mipmapを使うことでオブジェクトとの交差判定までのレイのステップ幅を可変にすることができます。こうすることで、限られたループ回数の中でも遠くまでレイを飛ばすことができるようになり、また処理効率も上がります。</p>
<p>RenderTextureからMipmapを使うデモシーンを用意してますのでそちらから確認していきましょう。</p>
<div class="emlist-code">
<p class="caption">Mipmap.cs</p>
<pre class="emlist">public class Mipmap : MonoBehaviour<font></font>
{<font></font>
  Material mat;<font></font>
  RenderTexture rt;<font></font>
  [SerializeField] Shader shader;<font></font>
  [SerializeField] int lod;<font></font>
<font></font>
  void OnEnable()<font></font>
  {<font></font>
    mat = new Material(shader);<font></font>
    rt = new RenderTexture(Screen.width, Screen.height, 24);<font></font>
    rt.useMipMap = true;<font></font>
  }<font></font>
<font></font>
  void OnDisable()<font></font>
  {<font></font>
    Destroy(mat);<font></font>
    rt.Release();<font></font>
  }<font></font>
<font></font>
  void OnRenderImage(RenderTexture src, RenderTexture dst)<font></font>
  {<font></font>
    mat.SetInt("_LOD", lod);<font></font>
    Graphics.Blit(src, rt);<font></font>
    Graphics.Blit(rt, dst, mat);<font></font>
  }<font></font>
}<font></font>
</pre>
</div>
<p>既製のRenderTextureに対してはmipmapは設定できないようになっているので、ここでは新しくRenderTextureを生成し <code class="inline-code tt">src</code> をコピーしたあと、処理を加えています。</p>
<div class="emlist-code">
<p class="caption">Mipmap.shader</p>
<pre class="emlist">sampler2D _MainTex;<font></font>
float4 _MainTex_ST;<font></font>
int _LOD;<font></font>
<font></font>
....<font></font>
<font></font>
fixed4 frag (v2f i) : SV_Target<font></font>
{<font></font>
        return tex2Dlod(_MainTex, float4(i.uv, 0, _LOD));<font></font>
}<font></font>
</pre>
</div>
<p><code class="inline-code tt">tex2Dlod(_MainTex, float4(i.uv, 0, _LOD))</code>でLODに応じたMipmapが取得できるようになってます。</p>
<p>シーン上でカメラにアタッチされたスクリプトからLODを上げていくと、画像が粗くなっていくのが確認できるかと思います。</p>
<div id="id_komietty_2Fssr__mipmap__demo" class="image">
<img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/ssr_mipmap_demo.png" alt="Comparison of LOD rise and Mipmap image quality">
<p class="caption">
図10.3: LODの上昇とMipmapの画質の比較
</p>
</div>
<p>Mipmapの使い方が確認できたところで、SSRシーンのなかでMipmapがどのように利用されているか見ていきましょう。</p>
<div class="emlist-code">
<p class="caption">SSR.shader</p>
<pre class="emlist">[loop]<font></font>
for (int n = 1; n &lt;= _MaxLoop; n++)<font></font>
{<font></font>
  float3 step = refDir * _RayLenCoeff * (lod + 1);<font></font>
  ray += step;<font></font>
<font></font>
  ....<font></font>
<font></font>
  if(rayDepth &lt; worldDepth)<font></font>
  {<font></font>
    if(lod == 0)<font></font>
    {<font></font>
      if (rayDepth + _Thickness &gt; worldDepth)<font></font>
      {<font></font>
        float sign = -1.0;<font></font>
        for (int m = 1; m &lt;= 8; ++m)<font></font>
        {<font></font>
          ray += sign * pow(0.5, m) * step;<font></font>
          rayScreen = mul(_ViewProj, float4(ray, 1.0));<font></font>
          rayUV = rayScreen.xy / rayScreen.w * 0.5 + 0.5;<font></font>
          rayDepth = ComputeDepth(rayScreen);<font></font>
          worldDepth = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, rayUV);<font></font>
          sign = (rayDepth &lt; worldDepth) ? -1 : 1;<font></font>
        }<font></font>
        refcol = tex2D(_MainTex, rayUV);<font></font>
      }<font></font>
      break;<font></font>
    }<font></font>
    else<font></font>
    {<font></font>
      ray -= step;<font></font>
      lod--;<font></font>
    }<font></font>
  }<font></font>
  else if(n &lt;= _MaxLOD)<font></font>
  {<font></font>
    lod++;<font></font>
  }<font></font>
  calcTimes = n;<font></font>
}<font></font>
if (_ViewMode == 3) return float4(1, 1, 1, 1) * calc / _MaxLoop;<font></font>
<font></font>
....<font></font>
<font></font>
</pre>
</div>
<p>Chalmersの記事にある図を用いて解説を進めていきます。</p>
<div id="id_komietty_2Fssr__mipmap__logic" class="image">
<img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/ssr_mipmap_logic.png" alt="Calculation method using Mipmap">
<p class="caption">
図10.4: Mipmapを用いた計算方法
</p>
</div>
<p>図のように、最初の数回は慎重に交差判定を行いながらLODを上げてきます。他メッシュとの交差が無いうちは、大きなステップのまま進めていきます。交差があった場合、UnityのMipMapは平均値を取りながら画素を荒くしていくので、記事の場合とは異なり、レイが行き過ぎてしまう場合があります。そのため一旦単位ステップ分後退し、再度一つ小さなLODでレイを進めます。最終的にLOD=0で画像で交差判定を行うことで、レイの移動距離を伸ばし、処理を効率化することができます。</p>
<p>メインカメラにアタッチされたスクリプトから、LODを上げた場合どのくらい計算量が変化するかが確認できるようになっています。計算量が多いほど白っぽく、少ないほど黒っぽく見えるようにしています。ViewMode を <code class="inline-code tt">CalcCount</code> にしてLODを変更しながら計算量の変化を確認してみて下さい。</p>
<div id="id_komietty_2Fssr__lod" class="image">
<img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/ssr_lod.png" alt="Difference in calculation amount due to change in LOD (the closer to black, the smaller the amount of calculation)">
<p class="caption">
図10.5: LODの変化による計算量の違い（黒に近いほど計算量が少ない）
</p>
</div>

<h3><a id="h10-3-5"></a><span class="secno">10.3.5　</span>二分木探索</h3>
<p>二分木探索で交差近傍の精度を上げていく方法を見ていきましょう。早速コードから確認します。</p>
<div class="emlist-code">
<p class="caption">SSR.shader</p>
<pre class="emlist">if (lod == 0)<font></font>
{<font></font>
  if (rayDepth + _Thickness &gt; worldDepth)<font></font>
  {<font></font>
    float sign = -1.0;<font></font>
    for (int m = 1; m &lt;= 8; ++m)<font></font>
    {<font></font>
      ray += sign * pow(0.5, m) * step;<font></font>
      rayScreen = mul(_ViewProj, float4(ray, 1.0));<font></font>
      rayUV = rayScreen.xy / rayScreen.w * 0.5 + 0.5;<font></font>
      rayDepth = ComputeDepth(rayScreen);<font></font>
      worldDepth = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, rayUV);<font></font>
      sign = (rayDepth &lt; worldDepth) ? -1 : 1;<font></font>
    }<font></font>
    refcol = tex2D(_MainTex, rayUV);<font></font>
  }<font></font>
  break;<font></font>
}<font></font>
</pre>
</div>
<p>交差の直後は交差したオブジェクトよりも奥にあるので、まずレイを後退させます。その後レイとメッシュとの前後関係を確認しながら、レイの進行方向を前後どちらか変更していきます。同時にレイのステップ幅を短くすることで、より少ない誤差でメッシュとの交差位置を特定することができます。</p>

<h3><a id="h10-3-6"></a><span class="secno">10.3.6　</span>マテリアルの違いを反映</h3>
<p>ここまでの方法ではスクリーン内のオブジェクトのマテリアルの違いは考慮していませんでした。そのため、全てのオブジェクトが同程度に反射してしまうという問題があります。そこで、再度G-bufferを使います。 <code class="inline-code tt">_CameraGBufferTexture1.w</code> にはマテリアルのsmoothnessが格納されているので、これを使います。</p>
<div class="emlist-code">
<p class="caption">SSR.shader</p>
<pre class="emlist">if (_ViewMode == 8)<font></font>
  return float4(1, 1, 1, 1) * tex2D(_CameraGBufferTexture1, uv).w;<font></font>
<font></font>
....<font></font>
<font></font>
return<font></font>
  (col * (1 - smooth) + refcol * smooth) * _ReflectionRate<font></font>
　+ col * (1 - _ReflectionRate);<font></font>
</pre>
</div>
<p>シーン内のオブジェクトに付帯しているマテリアルのsmoothnessの値を変更すると、そのオブジェクトだけ反射の程度が変更しているのが見て取れます。またメインカメラにアタッチされたスクリプトのViewMode を <code class="inline-code tt">Smoothness</code> にすることで、シーン内のsmoothnessを一覧できます。白っぽいほどsmoothnessが大きくなっています。</p>

<h3><a id="h10-3-7"></a><span class="secno">10.3.7　</span>Blur処理</h3>
<p>第一節で解説したガウシアンブラー使用している部分です。レイのステップ幅が十分小さくない場合、二分木探索を行っても反射をうまく取得できないことがあります。レイのステップ幅を小さくするとレイの全長が短くなってしまい、また計算量も増えるので、ステップ幅はただ小さくすれば良いというものではなく、適当な小ささにとどめておく必要があります。反射を上手く取得できなかった部分はブラー処理を掛けて、それらしく見せていきます。</p>
<div class="emlist-code">
<p class="caption">SSR.shader</p>
<pre class="emlist">float4 xblur(v2f i) : SV_Target<font></font>
{<font></font>
  float2 uv = i.screen.xy / i.screen.w;<font></font>
  float2 size = _ReflectionTexture_TexelSize;<font></font>
  float smooth = tex2D(_CameraGBufferTexture1, uv).w;<font></font>
<font></font>
  // compare depth<font></font>
  float depth = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, uv);<font></font>
  float depthR =<font></font>
        SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, uv + float2(1, 0) * size);<font></font>
  float depthL =<font></font>
        SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, uv - float2(1, 0) * size);<font></font>
<font></font>
  if (depth &lt;= 0) return tex2D(_ReflectionTexture, uv);<font></font>
<font></font>
  float weight[5] = { 0.2270270, 0.1945945, 0.1216216, 0.0540540, 0.0162162 };<font></font>
  float offset[5] = { 0.0, 1.0, 2.0, 3.0, 4.0 };<font></font>
<font></font>
  float4 originalColor = tex2D(_ReflectionTexture, uv);<font></font>
  float4 blurredColor = tex2D(_ReflectionTexture, uv) * weight[0];<font></font>
<font></font>
  for (int j = 1; j &lt; 5; ++j)<font></font>
  {<font></font>
    blurredColor<font></font>
        += tex2D(_ReflectionTexture, uv + float2(offset[j], 0) * size)<font></font>
           * weight[j];<font></font>
<font></font>
    blurredColor<font></font>
        += tex2D(_ReflectionTexture, uv - float2(offset[j], 0) * size)<font></font>
           * weight[j];<font></font>
  }<font></font>
<font></font>
  float4 o = (abs(depthR - depthL) &gt; _BlurThreshold) ? originalColor<font></font>
  　　　　　　　: blurredColor * smooth + originalColor * (1 - smooth);<font></font>
  return o;<font></font>
}<font></font>
</pre>
</div>
<p>ここでも前述の理由から <code class="inline-code tt">xblur</code> と <code class="inline-code tt">yblur</code> で処理を分けています。またブラー処理を掛けたいのは同一の反射面内のみなので、輪郭部分にはブラー処理が行われないようにしています。左右のデプスの差分が大きい場合、輪郭部分と判定しています。（ <code class="inline-code tt">yblur</code> では上下の差分を評価しています。）</p>
<p>ここまでの処理を追加した結果が以下になります。</p>
<div id="id_komietty_2Fssr__result" class="image">
<img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/ssr_result.png" alt="result">
<p class="caption">
図10.6: 結果
</p>
</div>

<h3><a id="h10-3-8"></a><span class="secno">10.3.8　</span>おまけ</h3>
<p>おまけ程度ですが、メインカメラとサブカメラの２台を使って、存在しないオブジェクトが写り込んでいるかのようなテクニックを紹介します。</p>
<div class="emlist-code">
<p class="caption">SSRMainCamera.shader</p>
<pre class="emlist">float4 reflection(v2f i) : SV_Target<font></font>
{<font></font>
<font></font>
  ....<font></font>
<font></font>
  for (int n = 1; n &lt;= 100; ++n)<font></font>
  {<font></font>
    float3 ray = n * step;<font></font>
    float3 rayPos = pos + ray;<font></font>
    float4 vpPos = mul(_ViewProj, float4(rayPos, 1.0));<font></font>
    float2 rayUv = vpPos.xy / vpPos.w * 0.5 + 0.5;<font></font>
    float rayDepth = vpPos.z / vpPos.w;<font></font>
    float subCameraDepth = SAMPLE_DEPTH_TEXTURE(_SubCameraDepthTex, rayUv);<font></font>
<font></font>
    if (rayDepth &lt; subCameraDepth &amp;&amp; rayDepth + thickness &gt; subCameraDepth)<font></font>
    {<font></font>
      float sign = -1.0;<font></font>
      for (int m = 1; m &lt;= 4; ++m)<font></font>
      {<font></font>
        rayPos += sign * pow(0.5, m) * step;<font></font>
        vpPos = mul(_ViewProj, float4(rayPos, 1.0));<font></font>
        rayUv = vpPos.xy / vpPos.w * 0.5 + 0.5;<font></font>
        rayDepth = vpPos.z / vpPos.w;<font></font>
        subCameraDepth = SAMPLE_DEPTH_TEXTURE(_SubCameraDepthTex, rayUv);<font></font>
        sign = rayDepth - subCameraDepth &lt; 0 ? -1 : 1;<font></font>
      }<font></font>
      col = tex2D(_SubCameraMainTex, rayUv);<font></font>
    }<font></font>
  }<font></font>
  return col * smooth + tex2D(_MainTex, uv) * (1 - smooth);<font></font>
}<font></font>
</pre>
</div>
<p>極力余分な処理を省いたシンプルな作りにしています。ポイントはデプス評価のために <code class="inline-code tt">SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, uv)</code> の代わりに <code class="inline-code tt">SAMPLE_DEPTH_TEXTURE(_SubCameraDepthTex, rayUv)</code> を使い、参照するオブジェクト情報も <code class="inline-code tt">_SubCameraMainTex</code> から取得している点です。<code class="inline-code tt">_CameraDepthTexture</code>, <code class="inline-code tt">_SubCameraDepthTex</code> はサブカメラからグローバルテクチャとしてセットしています。</p>
<p>欠点は、お互いのカメラが影になって映るべきでないオブジェクトも写してしまう点です。実用性はそれほどないかもしれませんが、ちょっとしたおもしろエフェクトということで。</p>
<div id="id_komietty_2Fssr__twocam" class="image">
<img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/ssr_twocam.png" alt="Method using two cameras">
<p class="caption">
図10.7: カメラ２台を用いた方法
</p>
</div>

<h2><a id="h10-4"></a><span class="secno">10.4　</span>まとめ</h2>
<p>以上でSSRの解説は終わりです。</p>
<p>SSRは大きな処理容量が必要になってくる手法のため、全ての位置にあるオブジェクトをきれいに反射させることは現実的ではありません。そこで、注目するオブジェクトの反射の見映えを良くしながら、些末な反射をいかに少ない処理でそれらしく見せるかがポイントになってきます。またレンダリングされるスクリーンサイズがそのまま計算量に直結するので、想定されるスクリーンサイズと、GPUの性能を加味しながら、映像として成立するポイントを探っていくことが重要です。シーン内のオブジェクトを動かしながら、パラメータを調整することで、各パラメータの役割とトレードオフを確認してみて下さい。</p>
<p>また、ここまでに挙げた、Mipmapや二分木探索、カメラバッファの使い方、その他数々の細かいテクニックはSSRに限らず様々なところで応用が利きます。読者の方々にとって部分的にでも参考になる内容があれば幸いです。</p>
<div class="footnote" epub:type="footnote" id="fn-gaussian"><p class="footnote">[*1] http://rastergrid.com/blog/2010/09/efficient-gaussian-blur-with-linear-sampling/</p></div>
<div class="footnote" epub:type="footnote" id="fn-binomial"><p class="footnote">[*2] https://ja.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E5%B8%83</p></div>
<div class="footnote" epub:type="footnote" id="fn-shirley"><p class="footnote">[*3] https://www.amazon.co.jp/gp/product/B01B5AODD8</p></div>
<div class="footnote" epub:type="footnote" id="fn-texel"><p class="footnote">[*4] https://msdn.microsoft.com/ja-jp/library/bb219690(v=vs.85).aspx</p></div>
<div class="footnote" epub:type="footnote" id="fn-reflection"><p class="footnote">[*5] https://www.sciencelearn.org.nz/resources/48-reflection-of-light</p></div>
<div class="footnote" epub:type="footnote" id="fn-kode80"><p class="footnote">[*6] http://www.kode80.com/blog/2015/03/11/screen-space-reflections-in-unity-5/</p></div>
<div class="footnote" epub:type="footnote" id="fn-chalmers"><p class="footnote">[*7] http://www.cse.chalmers.se/edu/year/2017/course/TDA361/　　　　　　Advanced%20Computer%20Graphics/Screen-space%20reflections.pdf</p></div>
<div class="footnote" epub:type="footnote" id="fn-hecomi"><p class="footnote">[*8] http://tips.hecomi.com/entry/2016/04/04/022550</p></div>
<div class="footnote" epub:type="footnote" id="fn-mipmap"><p class="footnote">[*9] https://answers.unity.com/questions/441984/what-is-mip-maps-pictures.html</p></div>
<div class="footnote" epub:type="footnote" id="fn-gbuffer"><p class="footnote">[*10] https://docs.unity3d.com/Manual/RenderTech-DeferredShading.html</p></div><div id="goog-gt-tt" class="skiptranslate" dir="ltr"><div style="padding: 8px;"><div><div class="logo"><img src="./Chapter 10 _ Application of ImageEffect (SSR)_files/translate_24dp.png" width="20" height="20" alt="Google Translate"></div></div></div><div class="top" style="padding: 8px; float: left; width: 100%;"><h1 class="title gray">Original text</h1></div><div class="middle" style="padding: 8px;"><div class="original-text"></div></div><div class="bottom" style="padding: 8px;"><div class="activity-links"><span class="activity-link">Contribute a better translation</span><span class="activity-link"></span></div><div class="started-activity-container"><hr style="color: #CCC; background-color: #CCC; height: 1px; border: none;"><div class="activity-root"></div></div></div><div class="status-message" style="display: none;"></div></div>


<div class="goog-te-spinner-pos"><div class="goog-te-spinner-animation"><svg xmlns="http://www.w3.org/2000/svg" class="goog-te-spinner" width="96px" height="96px" viewBox="0 0 66 66"><circle class="goog-te-spinner-path" fill="none" stroke-width="6" stroke-linecap="round" cx="33" cy="33" r="30"></circle></svg></div></div><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 1001px; height: 263px; display: none;" src="./Chapter 10 _ Application of ImageEffect (SSR)_files/saved_resource(1).html"></iframe><iframe frameborder="0" class="goog-te-menu-frame skiptranslate" title="Language Translate Widget" style="visibility: visible; box-sizing: content-box; width: 197px; height: 69px; display: none;" src="./Chapter 10 _ Application of ImageEffect (SSR)_files/saved_resource(2).html"></iframe></body></html>